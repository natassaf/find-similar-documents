{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad663e08-016f-4cb0-8973-30eb44208a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lit, row_number\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750df16f-b7a7-4911-b93b-5bf8a0ceb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.appName(\n",
    "# \"Analyzing the vocabulary of Pride and Prejudice.\"\n",
    "# ).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa872774-7128-483d-85e5-f8c97a826817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shingler:\n",
    "    def __init__(self, k):\n",
    "        self.shinglings_hashes = dict() # hash function is just  converting the shingle to a unique integer\n",
    "        self.hash_to_shingle = {}\n",
    "        self.shingle_hash_start_number = 0\n",
    "        self.k = k\n",
    "        \n",
    "    def hash_shingle(self,shingle):\n",
    "        if shingle in self.shinglings_hashes:\n",
    "            return self.shinglings_hashes[shingle]\n",
    "        else:\n",
    "            self.shinglings_hashes[shingle] = self.shingle_hash_start_number\n",
    "            self.hash_to_shingle[self.shingle_hash_start_number] = shingle\n",
    "            self.shingle_hash_start_number += 1\n",
    "            return self.shingle_hash_start_number - 1\n",
    "            \n",
    "    def to_binary_shingle(self, document):\n",
    "        all_shingles = self.get_all_shingles()\n",
    "        binary_shingles = []\n",
    "        for shingle in all_shingles:\n",
    "            if shingle in document:\n",
    "                binary_shingles.append(1)\n",
    "            else:\n",
    "                binary_shingles.append(0)\n",
    "        assert len(binary_shingles) == len(all_shingles)\n",
    "        return binary_shingles\n",
    "\n",
    "    def get_all_shingles(self):\n",
    "        return list(range(0, self.shingle_hash_start_number))\n",
    "    \n",
    "    def create_shingles(self, document): \n",
    "        shingles = set()\n",
    "        un_shingles = set()\n",
    "        for i in range(0, len(document)-self.k+1 ):\n",
    "            un_shingles.add(document[i:i+self.k])\n",
    "            shingles.add(self.hash_shingle(document[i:i+self.k]))\n",
    "        return shingles\n",
    "\n",
    "    def to_text(self, s):\n",
    "        return self.hash_to_shingle[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14873a9a-a90e-410b-ba3b-61d5a6e9e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jaccard_similarity(A,B):\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "def find_jaccard_similarity_matrix(signatures):\n",
    "    jaccard_similarity_matrix = np.full((len(signatures), len(signatures)), -1.0)\n",
    "    for i in range(0, len(signatures)):\n",
    "        doci = signatures[i]\n",
    "        for j in range(0, len(signatures)):\n",
    "            if i==j:\n",
    "                jaccard_similarity_matrix[i,j]=None\n",
    "            else:\n",
    "                docj = signatures[j]\n",
    "                jaccard_similarity_matrix[i,j] = find_jaccard_similarity(doci, docj)\n",
    "    return jaccard_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44946d41-05ed-4782-8202-c26fbae8c49b",
   "metadata": {},
   "source": [
    "## Part 1: Represent all documents as a  vector of ordered set of shingles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500a66e-e5d1-467f-84ea-1056c6cb1b00",
   "metadata": {},
   "source": [
    "In this part we represent each document as a vector of shingles with size 3. Then we map each shingle to a number for memory optimization.\n",
    "The execution time is: 0.0063860416412353516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca86bd5-58e1-44f6-89d3-d7d3864806ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and shingle documents \n",
    "all_documents = []\n",
    "documents_path = \"../news_dataset\"\n",
    "k=3\n",
    "shingler = Shingler(k)\n",
    "all_files = []\n",
    "for i in range(1,8):\n",
    "    with open(f\"{documents_path}/{i}.txt\", \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        all_files.append(file_contents)\n",
    "        shingles = shingler.create_shingles(file_contents)\n",
    "        all_documents.append(shingles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85136192-7648-47d5-8de5-b8955fc02682",
   "metadata": {},
   "source": [
    "## Part 2: Find Jaccard similarity between sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea9916-fbfc-4977-8ed7-27c0735c2c6e",
   "metadata": {},
   "source": [
    "In this part using the shingles we calculate the jaccard similarity matrix for our 7 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ca7906-75c8-417a-9077-626020beebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard execution time: 0.0063860416412353516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326294</td>\n",
       "      <td>0.224566</td>\n",
       "      <td>0.220258</td>\n",
       "      <td>0.216453</td>\n",
       "      <td>0.220054</td>\n",
       "      <td>0.255163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.185662</td>\n",
       "      <td>0.231877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.224566</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206335</td>\n",
       "      <td>0.211191</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.212276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.220258</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.206335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554813</td>\n",
       "      <td>0.504493</td>\n",
       "      <td>0.199807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216453</td>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.211191</td>\n",
       "      <td>0.554813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>0.201536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.220054</td>\n",
       "      <td>0.185662</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.504493</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.194129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.255163</td>\n",
       "      <td>0.231877</td>\n",
       "      <td>0.212276</td>\n",
       "      <td>0.199807</td>\n",
       "      <td>0.201536</td>\n",
       "      <td>0.194129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0       NaN  0.326294  0.224566  0.220258  0.216453  0.220054  0.255163\n",
       "1  0.326294       NaN  0.210689  0.192182  0.186981  0.185662  0.231877\n",
       "2  0.224566  0.210689       NaN  0.206335  0.211191  0.213836  0.212276\n",
       "3  0.220258  0.192182  0.206335       NaN  0.554813  0.504493  0.199807\n",
       "4  0.216453  0.186981  0.211191  0.554813       NaN  0.539765  0.201536\n",
       "5  0.220054  0.185662  0.213836  0.504493  0.539765       NaN  0.194129\n",
       "6  0.255163  0.231877  0.212276  0.199807  0.201536  0.194129       NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_start = time.time()\n",
    "jaccard_similarity_matrix = find_jaccard_similarity_matrix(all_documents)\n",
    "jaccard_end = time.time()\n",
    "\n",
    "print(f\"Jaccard execution time: {jaccard_end- jaccard_start}\")\n",
    "\n",
    "jaccard_df = pd.DataFrame(jaccard_similarity_matrix)\n",
    "jaccard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b6ffa-2746-4247-97c3-90df82f2661e",
   "metadata": {},
   "source": [
    "## Part 3: MinHashing Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43032330-0c3d-4983-8478-2dcb28fed571",
   "metadata": {},
   "source": [
    "### Min hash similarity calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3dbe9b-1f73-4e52-a4ef-9525482beaff",
   "metadata": {},
   "source": [
    "In this part we calculate minhash similarity matrix. To create the signatures we use 500 hash functions. The process is the following:\n",
    "1) For each document for each single apply a hash function and get the min value\n",
    "2) Do this for 500 hash functions\n",
    "3) Concatenate these min values in a vector which is now the signature of each document\n",
    "\n",
    "Then we use the signature of each document to compare the documents to each and produce a similarity matrix. The minhash similarity formula:\n",
    "S_i(doc1_i == doc2_i)/n where n in the signature length\n",
    "\n",
    "Minhash similarity execution time: 0.2787048816680908"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935829ee-1275-47b3-ac65-de9880a476d7",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f04dd-40fd-4e48-82fc-e81c54c0d72b",
   "metadata": {},
   "source": [
    "In order to find the number of hash functions for which the minhash similirity is closer to the jaccard similarity we try many parameters and keep the one that minimizes the mean squared error on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c070d0-07e5-46f0-970d-d39c1066bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c62258-a08a-40af-8e32-1b99d86877c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHash:\n",
    "\n",
    "    def __init__(self, a, b):\n",
    "        self.a= a\n",
    "        self.b = b\n",
    "        self.c = 21323\n",
    "\n",
    "    def hash(self, element):\n",
    "        return (self.a * element + self.b) % self.c\n",
    "\n",
    "    def get_min_hash(self, document):\n",
    "        min_hash = np.inf\n",
    "        for shingle in document:\n",
    "            hash_value = self.hash(shingle)\n",
    "            if hash_value < min_hash:\n",
    "                min_hash = hash_value\n",
    "        return min_hash\n",
    "\n",
    "class Signature:\n",
    "    def __init__(self, hash_funcs):\n",
    "        self.hash_funcs = hash_funcs\n",
    "\n",
    "    def get_signature(self, document):\n",
    "        doc_signature = []\n",
    "        for hashf in self.hash_funcs:\n",
    "            min_hash = hashf.get_min_hash(document)\n",
    "            doc_signature.append(min_hash)\n",
    "        return doc_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abab7803-b5a5-43b1-a40c-20f72569c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create signature matrix\n",
    "\n",
    "\n",
    "def create_signatures(all_documents, k):\n",
    "    hash_funcs = [MyHash(i+10, i+30) for i in  range(0, k)]\n",
    "    signature_builder = Signature(hash_funcs)\n",
    "    signatures = []\n",
    "    for document in all_documents:\n",
    "        doc_signature = signature_builder.get_signature(document)\n",
    "        signatures.append(doc_signature)\n",
    "    assert len(signatures) == len(all_documents)\n",
    "    assert len(signatures[0]) == len(signatures[1]) == k\n",
    "    return signatures\n",
    "\n",
    "def calculate_min_hash_similarity(signatures):\n",
    "    signatures = np.array(signatures)\n",
    "    similarity_matrix = np.full((len(signatures), len(signatures)), -1.0)\n",
    "    for i, doc1 in enumerate(signatures):\n",
    "        for j, doc2 in enumerate(signatures):\n",
    "            if i==j:\n",
    "                similarity_matrix[i,j] = None\n",
    "            else:\n",
    "                doc1 = np.array(doc1)\n",
    "                doc2 = np.array(doc2)\n",
    "                similarity =  sum(doc1 == doc2)/len(doc1)\n",
    "                similarity_matrix[i,j] = similarity\n",
    "    return similarity_matrix\n",
    "\n",
    "def mean_error(signatures, similarity_matrix, jaccard_similarity_matrix ):\n",
    "    mean_squared_error = 0\n",
    "    counter=0\n",
    "    for i in range(0, len(signatures)):\n",
    "        for j in range(0, len(signatures)):\n",
    "            if i>=j:\n",
    "                continue\n",
    "            minhash = similarity_matrix[i,j]\n",
    "    \n",
    "            jaccard = jaccard_similarity_matrix[i][j]\n",
    "            mean_squared_error = mean_squared_error + (minhash-jaccard)**2\n",
    "            counter +=1\n",
    "    error = mean_squared_error/counter\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fd029-85df-4062-9bd9-f35e3f99be74",
   "metadata": {},
   "source": [
    "### Tune number of hash functions parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640e1fae-f83b-4213-b3dd-611b1b7ef840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min error for 500: 0.0005424679368489426\n"
     ]
    }
   ],
   "source": [
    "# compare documents\n",
    "def tune_num_hash_funcs(all_documents): \n",
    "    num_hash_func = [100,200,300,400,500]\n",
    "    min_error = np.inf\n",
    "    for k in num_hash_func:\n",
    "        signatures = create_signatures(all_documents, k)\n",
    "        similarity_matrix = calculate_min_hash_similarity(signatures)\n",
    "        error = mean_error(signatures, similarity_matrix, jaccard_similarity_matrix )\n",
    "        if error<min_error:\n",
    "            best_num = k\n",
    "            min_error = error\n",
    "    \n",
    "    print(f\"min error for {best_num}: {min_error}\") \n",
    "    return best_num\n",
    "    \n",
    "num_hash = tune_num_hash_funcs(all_documents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba335856-b0b8-417a-9634-c438d286eb4a",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f18f2d50-3ef1-47a9-856d-95df74bc97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minhash similarity execution time: 0.2787048816680908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326294</td>\n",
       "      <td>0.224566</td>\n",
       "      <td>0.220258</td>\n",
       "      <td>0.216453</td>\n",
       "      <td>0.220054</td>\n",
       "      <td>0.255163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.185662</td>\n",
       "      <td>0.231877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.224566</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206335</td>\n",
       "      <td>0.211191</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.212276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.220258</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.206335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554813</td>\n",
       "      <td>0.504493</td>\n",
       "      <td>0.199807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216453</td>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.211191</td>\n",
       "      <td>0.554813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>0.201536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.220054</td>\n",
       "      <td>0.185662</td>\n",
       "      <td>0.213836</td>\n",
       "      <td>0.504493</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.194129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.255163</td>\n",
       "      <td>0.231877</td>\n",
       "      <td>0.212276</td>\n",
       "      <td>0.199807</td>\n",
       "      <td>0.201536</td>\n",
       "      <td>0.194129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0       NaN  0.326294  0.224566  0.220258  0.216453  0.220054  0.255163\n",
       "1  0.326294       NaN  0.210689  0.192182  0.186981  0.185662  0.231877\n",
       "2  0.224566  0.210689       NaN  0.206335  0.211191  0.213836  0.212276\n",
       "3  0.220258  0.192182  0.206335       NaN  0.554813  0.504493  0.199807\n",
       "4  0.216453  0.186981  0.211191  0.554813       NaN  0.539765  0.201536\n",
       "5  0.220054  0.185662  0.213836  0.504493  0.539765       NaN  0.194129\n",
       "6  0.255163  0.231877  0.212276  0.199807  0.201536  0.194129       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.240</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6\n",
       "0    NaN  0.342  0.236  0.266  0.250  0.240  0.238\n",
       "1  0.342    NaN  0.254  0.222  0.218  0.216  0.264\n",
       "2  0.236  0.254    NaN  0.204  0.200  0.212  0.210\n",
       "3  0.266  0.222  0.204    NaN  0.544  0.474  0.196\n",
       "4  0.250  0.218  0.200  0.544    NaN  0.526  0.206\n",
       "5  0.240  0.216  0.212  0.474  0.526    NaN  0.198\n",
       "6  0.238  0.264  0.210  0.196  0.206  0.198    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "min_hash_start = time.time()\n",
    "signatures = create_signatures(all_documents, num_hash)\n",
    "similarity_matrix = calculate_min_hash_similarity(signatures)\n",
    "min_hash_end = time.time()\n",
    "print(f\"Minhash similarity execution time: {min_hash_end - min_hash_start}\") \n",
    "\n",
    "similarity_matrix_df = pd.DataFrame(similarity_matrix)\n",
    "display(jaccard_df), display(similarity_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c82f93-c260-4e4e-8bcb-ed2b4b1b74a9",
   "metadata": {},
   "source": [
    "## LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee59e14-fedc-4c5e-b18a-3ba09ac56c6c",
   "metadata": {},
   "source": [
    "### Part 4: Find neighbor documents using LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f8e0c-2c1a-48e4-97d6-eb2bf79d0524",
   "metadata": {},
   "source": [
    "In this part we implement LSH in the following manner:\n",
    "1) we separate the signatures into bands\n",
    "2) for each pair of documents we go through the bands and hash each band to a number. If both document's hash are the same then we consider them possibly similar documents and we will compare them.\n",
    "\n",
    "Tuning:\n",
    "In order to find the optimal number of bands and the optimal number of buckets we try many settings and we minimize the number of false positives\n",
    "\n",
    "The time to execute LSH is: 0.00528407096862793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51d12c5-dc1b-4255-a202-e35b4b076112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bands(signature, b):\n",
    "    step = len(signature) // b\n",
    "    signature_in_bands = []   \n",
    "    for i in range(0, len(signature), step):\n",
    "        signature_in_bands.append(signature[i:i+step])\n",
    "    if i+k < len(signature):\n",
    "        signature_in_bands[-1].extend(signature[i+step:-1]) \n",
    "    return signature_in_bands\n",
    "\n",
    "class CustomHash:\n",
    "    def __init__(self, num_buckets):\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "    def hash(self, value):\n",
    "        return hash(frozenset(value)) % self.num_buckets\n",
    "        \n",
    "def are_docs_possibly_similar(sign1, sign2, myhash):  \n",
    "    pairs_to_compare = []\n",
    "    c = 0\n",
    "    for band1, band2 in zip(sign1,sign2):\n",
    "        b1 = myhash.hash(band1)\n",
    "        b2 = myhash.hash(band2)\n",
    "        # print(f\"band2: {band2}, b2: {b2}\")\n",
    "        if b1 == b2:\n",
    "            # print(\"c: \", c)\n",
    "            return True\n",
    "        c+=1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc7defd-ce8e-4298-b2f0-ac146ebaf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lsh(signatures, num_bands, num_hash_buckets):\n",
    "    all_signatures_in_bands = list(map(lambda x: build_bands(x, num_bands), signatures))\n",
    "    myhash = CustomHash(num_hash_buckets)\n",
    "\n",
    "    compare_to_map = {}\n",
    "    for i, doc1_sign in enumerate(all_signatures_in_bands):\n",
    "        compare_to_map[i] = []\n",
    "        for j, doc2_sign in enumerate(all_signatures_in_bands):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if are_docs_possibly_similar(doc1_sign, doc2_sign, myhash):\n",
    "                if j not in compare_to_map[i]:\n",
    "                    compare_to_map[i].append(j)\n",
    "                # compare_to.append(((i, signatures[i]), (j, signatures[j])))\n",
    "    return compare_to_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aaf4112-78f0-4acd-9772-90e932268800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_false_negatives_positives(expected, result):\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    for k,v in expected.items():\n",
    "        found_neighbors = set(result[k])\n",
    "        expected_neighbors = set(expected[k])\n",
    "        false_negatives += len(expected_neighbors - found_neighbors)\n",
    "        false_positives += len(found_neighbors - expected_neighbors)\n",
    "    return false_negatives, false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb29b2a-bc83-4845-8d86-49d06b8f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_similar_docs = [(0,1,6), (3,4,5), (2)]\n",
    "expected_result = {0:[1,6], 1:[0,6], 2:[], 3:[4,5], 4:[3,5], 5:[3,4], 6:[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eef5d16-ef77-4127-a3d0-3bb68cb01a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best settings (num_bands, num_hash_buckets ): (100, 997), Minimum false negatives: 0\n"
     ]
    }
   ],
   "source": [
    "def tune_lsh(signatures):\n",
    "    expected = {0:[1,6], 1:[0,6], 2:[], 3:[4,5], 4:[3,5], 5:[3,4], 6:[1]}\n",
    "    possible_num_bands = [25, 50, 75, 100, 110,  115, 120, 125, 130, 150, 175, 200]\n",
    "    possible_num_hash_buckets = [1,743,827,911,997,1097,1187,1277,1367,1451,1543,1627,1721,1811,1901,1997,2087,2179]\n",
    "    best_settings = []\n",
    "    min_false_neg = np.inf\n",
    "    min_false_pos = np.inf\n",
    "    for num_bands in possible_num_bands:\n",
    "        for num_hash_buckets in possible_num_hash_buckets:  \n",
    "            result = run_lsh(signatures, num_bands, num_hash_buckets)\n",
    "            num_false_neg, num_false_pos = find_false_negatives_positives(expected, result)\n",
    "            if num_false_neg < min_false_neg:\n",
    "                min_false_neg = num_false_neg\n",
    "                min_false_pos = num_false_pos\n",
    "                best_settings=(num_bands,num_hash_buckets)\n",
    "            elif num_false_neg == min_false_neg:\n",
    "                if num_false_pos < min_false_pos:\n",
    "                    min_false_neg = num_false_neg\n",
    "                    min_false_pos = num_false_pos\n",
    "                    best_settings = (num_bands,num_hash_buckets)\n",
    "    return best_settings,  min_false_neg, min_false_pos\n",
    "best_settings, min_false_neg, min_false_pos = tune_lsh(signatures)  \n",
    "print(f\"Best settings (num_bands, num_hash_buckets ): {best_settings}, Minimum false negatives: {min_false_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3610cfc-ad4c-42d7-b55e-c00f8564f0d0",
   "metadata": {},
   "source": [
    "### Run LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78bdafb8-f8fc-48d2-94de-d591d6c8b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSH  execution time: 0.00528407096862793\n",
      "Result: {0: [1, 3, 6], 1: [0, 3, 4, 6], 2: [], 3: [0, 1, 4, 5], 4: [1, 3, 5], 5: [3, 4], 6: [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "num_bands, num_hash_buckets = best_settings\n",
    "lsh_start = time.time()\n",
    "result = run_lsh(signatures, num_bands, num_hash_buckets)\n",
    "lsh_stop = time.time()\n",
    "print(f\"LSH  execution time: {lsh_stop - lsh_start}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460c63a-56a4-4f0e-8eb7-819efcfc45d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
